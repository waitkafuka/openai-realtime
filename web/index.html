<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>实时语音交互</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
            font-family: Arial, sans-serif;
        }

        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 100%;
            max-width: 600px;
            /* 添加最大宽度 */
            padding: 20px;
            /* 添加内边距 */
        }

        #talkButton {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background: linear-gradient(145deg, #f0f0f0, #cacaca);
            box-shadow: 20px 20px 60px #bebebe, -20px -20px 60px #ffffff;
            border: none;
            outline: none;
            cursor: pointer;
            font-size: 16px;
            color: #333;
            transition: all 0.3s ease;
        }

        #talkButton:active {
            box-shadow: inset 20px 20px 60px #bebebe, inset -20px -20px 60px #ffffff;
        }

        #waveform,
        #messageContainer {
            width: 100%;
            /* 改为100%宽度 */
            height: 100px;
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 20px;
        }

        #textInput {
            width: 300px;
            height: 100px;
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            resize: none;
            font-size: 14px;
        }

        #sendButton {
            margin-top: 10px;
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }

        #sendButton:hover {
            background-color: #45a049;
        }

        #messageContainer {
            box-sizing: border-box;
            width: 100%;
            /* 改为100%宽度 */
            height: 200px;
            margin-top: 20px;
            overflow-y: auto;
            background-color: #fff;
            padding: 10px;
        }

        .message,
        .error-message {
            margin-bottom: 10px;
            padding: 5px;
            border-radius: 5px;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .message {
            background-color: #e6f3ff;
        }

        .error-message {
            background-color: #ffebee;
            color: #d32f2f;
        }

        .timestamp {
            font-size: 0.8em;
            color: #666;
            margin-right: 5px;
        }
    </style>
</head>

<body>
    <div class="container">
        <button id="talkButton">按住说话</button>
        <canvas id="waveform"></canvas>
        <div id="messageContainer"></div>
        <!-- <textarea id="textInput" placeholder="输入文本消息..."></textarea> -->
        <!-- <button id="sendButton">发送</button> -->
    </div>
    <script>
        // Existing variables
        let audioContext;
        let audioBufferQueue = [];
        let isPlaying = false;

        // Add these variables for playback visualizer
        let playbackAnalyser = null;
        let playbackDataArray;
        let visualizerAnimationFrame;

        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
            }
        }

        // Convert PCM16 (Int16Array) to Float32Array
        function convertPCM16ToFloat32(pcm16Array) {
            var float32Array = new Float32Array(pcm16Array.length);
            for (var i = 0; i < pcm16Array.length; i++) {
                var int = pcm16Array[i];
                // Convert Int16 range (-32768 to 32767) to Float32 range (-1.0 to 1.0)
                float32Array[i] = int / 32768;
            }
            return float32Array;
        }

        // Create AudioBuffer synchronously
        function createAudioBuffer(audioContext, float32Array, sampleRate, numChannels) {
            var frameCount = float32Array.length / numChannels;
            // Create AudioBuffer
            var audioBuffer = audioContext.createBuffer(numChannels, frameCount, sampleRate);

            // Fill AudioBuffer with data
            for (var channel = 0; channel < numChannels; channel++) {
                var channelData = audioBuffer.getChannelData(channel);
                for (var i = 0; i < frameCount; i++) {
                    channelData[i] = float32Array[i * numChannels + channel];
                }
            }

            return audioBuffer;
        }

        // Modified function to play audio buffer with visualizer
        function playAudioFromBase64PCM16(base64PCMData, sampleRate = 24000, numChannels = 1) {
            initAudioContext();

            const pcmArrayBuffer = base64ToArrayBuffer(base64PCMData);
            // Create Int16Array
            var pcm16Array = new Int16Array(pcmArrayBuffer);
            const float32Array = convertPCM16ToFloat32(pcm16Array);

            // Create AudioBuffer and add to queue
            const audioBuffer = createAudioBuffer(audioContext, float32Array, sampleRate, numChannels);
            audioBufferQueue.push(audioBuffer);
            if (!isPlaying) {
                playNextAudioBuffer();
            }
        }

        function playNextAudioBuffer() {
            if (audioBufferQueue.length === 0) {
                isPlaying = false;
                // Stop drawing waveform
                stopVisualizer();
                return;
            }

            isPlaying = true;
            const audioBuffer = audioBufferQueue.shift();
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;

            // Create analyser node if not already created
            if (!playbackAnalyser) {
                playbackAnalyser = audioContext.createAnalyser();
                playbackAnalyser.fftSize = 256; // Can adjust this value
                playbackDataArray = new Uint8Array(playbackAnalyser.frequencyBinCount);
            }

            // Connect source -> analyser -> destination
            source.connect(playbackAnalyser);
            playbackAnalyser.connect(audioContext.destination);

            source.onended = playNextAudioBuffer;
            source.start(0);

            // Start drawing waveform if not already started
            if (!visualizerAnimationFrame) {
                drawPlaybackWaveform();
            }
        }

        function drawPlaybackWaveform() {
            visualizerAnimationFrame = requestAnimationFrame(drawPlaybackWaveform);

            playbackAnalyser.getByteTimeDomainData(playbackDataArray);
            drawWaveform(playbackDataArray);
        }

        function stopVisualizer() {
            if (visualizerAnimationFrame) {
                cancelAnimationFrame(visualizerAnimationFrame);
                visualizerAnimationFrame = null;
            }
            playbackAnalyser = null; // Reset analyser
            waveformCtx.clearRect(0, 0, waveform.width, waveform.height);
        }

        // WebSocket connection to the server
        const ws = new WebSocket('ws://localhost:3000'); // Update as needed

        ws.onopen = function () {
            console.log('Connected to the server.');
        };

        let currentMessageElement = null;

        ws.onmessage = function (event) {
            const data = JSON.parse(event.data);
            if (data.type === 'audio') {
                console.log('Received audio data:', data.audio.length);
                playAudioFromBase64PCM16(data.audio);
            } else if (data.type === 'text') {
                console.log('Received text message:', data.content);
                appendMessage(data.content);
            } else if (data.type === 'error') {
                console.error('Server error:', data.message);
                // appendMessage('Error: ' + data.message, true);
            } else if (data.type === 'response.audio_transcript.done') {
                finishCurrentMessage();
            }
        };

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // Button event handling
        let recording = false;
        let processor;
        let analyser;

        const button = document.getElementById('talkButton');
        const waveform = document.getElementById('waveform');
        const waveformCtx = waveform.getContext('2d');

        button.addEventListener('mousedown', startRecording);
        button.addEventListener('mouseup', stopRecording);
        button.addEventListener('mouseleave', stopRecording); // Stop recording if mouse leaves the button
        button.addEventListener('touchstart', startRecording);
        button.addEventListener('touchend', stopRecording);

        function startRecording() {
            if (recording) return;
            recording = true;
            button.textContent = 'Release to Send';

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(function (stream) {
                    initAudioContext();
                    const source = audioContext.createMediaStreamSource(stream);
                    processor = audioContext.createScriptProcessor(2048, 1, 1);
                    analyser = audioContext.createAnalyser();

                    analyser.fftSize = 256;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);

                    source.connect(analyser);
                    analyser.connect(processor);
                    processor.connect(audioContext.destination);

                    processor.onaudioprocess = function (e) {
                        if (!recording) return;
                        const float32Array = e.inputBuffer.getChannelData(0);
                        const base64Audio = base64EncodeAudio(float32Array);
                        ws.send(JSON.stringify({ type: 'audio', audio: base64Audio }));

                        // Update waveform during recording
                        analyser.getByteTimeDomainData(dataArray);
                        drawWaveform(dataArray);
                    };
                })
                .catch(function (err) {
                    console.log('Error: ' + err);
                });
        }

        function stopRecording() {
            if (!recording) return;
            recording = false;
            button.textContent = 'Hold to Talk';

            // Stop all audio processing
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (analyser) {
                analyser.disconnect();
                analyser = null;
            }
            if (audioContext) {
                audioContext.close().then(() => {
                    audioContext = null;
                    console.log('AudioContext has been closed.');
                });
            }

            // Send audio end signal
            ws.send(JSON.stringify({ type: 'audio_commit' }));

            // Clear waveform
            waveformCtx.clearRect(0, 0, waveform.width, waveform.height);

            console.log('Recording stopped and committed.');
        }

        function drawWaveform(dataArray) {
            waveformCtx.fillStyle = 'rgb(200, 200, 200)';
            waveformCtx.fillRect(0, 0, waveform.width, waveform.height);

            waveformCtx.lineWidth = 2;
            waveformCtx.strokeStyle = 'rgb(0, 0, 0)';

            waveformCtx.beginPath();

            const sliceWidth = waveform.width * 1.0 / dataArray.length;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * waveform.height / 2;

                if (i === 0) {
                    waveformCtx.moveTo(x, y);
                } else {
                    waveformCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            waveformCtx.lineTo(waveform.width, waveform.height / 2);
            waveformCtx.stroke();
        }

        function floatTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            for (let i = 0; i < float32Array.length; i++) {
                let s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            return buffer;
        }

        function base64EncodeAudio(float32Array) {
            const buffer = floatTo16BitPCM(float32Array);
            let binary = '';
            const bytes = new Uint8Array(buffer);
            for (let i = 0; i < bytes.byteLength; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        // Adjust canvas size
        function resizeCanvas() {
            waveform.width = waveform.clientWidth;
            waveform.height = waveform.clientHeight;
        }

        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();

        const textInput = document.getElementById('textInput');
        const sendButton = document.getElementById('sendButton');

        sendButton.addEventListener('click', sendTextMessage);

        function sendTextMessage() {
            const text = textInput.value.trim();
            if (text) {
                ws.send(JSON.stringify({ type: 'text', content: text }));
                textInput.value = '';
            }
        }

        function appendMessage(message, isError = false) {
            const messageContainer = document.getElementById('messageContainer');

            if (!currentMessageElement) {
                currentMessageElement = document.createElement('div');
                currentMessageElement.className = isError ? 'error-message' : 'message';

                // Add timestamp
                const timestamp = new Date().toLocaleTimeString();
                const timestampElement = document.createElement('span');
                timestampElement.className = 'timestamp';
                timestampElement.textContent = `[${timestamp}] `;

                currentMessageElement.appendChild(timestampElement);
                messageContainer.appendChild(currentMessageElement);
            }

            // Add message content
            const messageContent = document.createElement('span');
            messageContent.textContent = message;
            currentMessageElement.appendChild(messageContent);

            messageContainer.scrollTop = messageContainer.scrollHeight;
        }

        function finishCurrentMessage() {
            currentMessageElement = null;
        }
    </script>
</body>

</html>